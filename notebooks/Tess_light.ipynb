{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edfb9fb3-6a74-4d25-b944-45273e8e64f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d7c4db-16ef-4b4a-988b-4da03f40adf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install xgboost\n",
    "!pip install catboost\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa9cef6-4915-4e78-9dc8-e8c9b3468c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c29f14-3757-47d2-beb3-569bbd9c38cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TESS (TOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "043ac514-47e8-4d7f-884b-0241ae75d099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7703, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_rowid</th>\n",
       "      <th>toi</th>\n",
       "      <th>tid</th>\n",
       "      <th>tfopwg_disp</th>\n",
       "      <th>rastr</th>\n",
       "      <th>ra</th>\n",
       "      <th>decstr</th>\n",
       "      <th>dec</th>\n",
       "      <th>st_pmra</th>\n",
       "      <th>st_pmraerr1</th>\n",
       "      <th>st_pmraerr2</th>\n",
       "      <th>st_pmralim</th>\n",
       "      <th>st_pmdec</th>\n",
       "      <th>st_pmdecerr1</th>\n",
       "      <th>st_pmdecerr2</th>\n",
       "      <th>st_pmdeclim</th>\n",
       "      <th>pl_tranmid</th>\n",
       "      <th>pl_tranmiderr1</th>\n",
       "      <th>pl_tranmiderr2</th>\n",
       "      <th>pl_tranmidlim</th>\n",
       "      <th>pl_orbper</th>\n",
       "      <th>pl_orbpererr1</th>\n",
       "      <th>pl_orbpererr2</th>\n",
       "      <th>pl_orbperlim</th>\n",
       "      <th>pl_trandurh</th>\n",
       "      <th>pl_trandurherr1</th>\n",
       "      <th>pl_trandurherr2</th>\n",
       "      <th>pl_trandurhlim</th>\n",
       "      <th>pl_trandep</th>\n",
       "      <th>pl_trandeperr1</th>\n",
       "      <th>pl_trandeperr2</th>\n",
       "      <th>pl_trandeplim</th>\n",
       "      <th>pl_rade</th>\n",
       "      <th>pl_radeerr1</th>\n",
       "      <th>pl_radeerr2</th>\n",
       "      <th>pl_radelim</th>\n",
       "      <th>pl_insol</th>\n",
       "      <th>pl_insolerr1</th>\n",
       "      <th>pl_insolerr2</th>\n",
       "      <th>pl_insollim</th>\n",
       "      <th>pl_eqt</th>\n",
       "      <th>pl_eqterr1</th>\n",
       "      <th>pl_eqterr2</th>\n",
       "      <th>pl_eqtlim</th>\n",
       "      <th>st_tmag</th>\n",
       "      <th>st_tmagerr1</th>\n",
       "      <th>st_tmagerr2</th>\n",
       "      <th>st_tmaglim</th>\n",
       "      <th>st_dist</th>\n",
       "      <th>st_disterr1</th>\n",
       "      <th>st_disterr2</th>\n",
       "      <th>st_distlim</th>\n",
       "      <th>st_teff</th>\n",
       "      <th>st_tefferr1</th>\n",
       "      <th>st_tefferr2</th>\n",
       "      <th>st_tefflim</th>\n",
       "      <th>st_logg</th>\n",
       "      <th>st_loggerr1</th>\n",
       "      <th>st_loggerr2</th>\n",
       "      <th>st_logglim</th>\n",
       "      <th>st_rad</th>\n",
       "      <th>st_raderr1</th>\n",
       "      <th>st_raderr2</th>\n",
       "      <th>st_radlim</th>\n",
       "      <th>toi_created</th>\n",
       "      <th>rowupdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1000.01</td>\n",
       "      <td>50365310</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>07h29m25.85s</td>\n",
       "      <td>112.357708</td>\n",
       "      <td>-12d41m45.46s</td>\n",
       "      <td>-12.695960</td>\n",
       "      <td>-5.964</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.459230e+06</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>0</td>\n",
       "      <td>2.171348</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>0</td>\n",
       "      <td>2.01722</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>-0.319588</td>\n",
       "      <td>0</td>\n",
       "      <td>656.886099</td>\n",
       "      <td>37.778210</td>\n",
       "      <td>-37.778210</td>\n",
       "      <td>0</td>\n",
       "      <td>5.818163</td>\n",
       "      <td>1.910546</td>\n",
       "      <td>-1.910546</td>\n",
       "      <td>0</td>\n",
       "      <td>22601.948581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3127.204052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.604000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0</td>\n",
       "      <td>485.735</td>\n",
       "      <td>11.9515</td>\n",
       "      <td>-11.9515</td>\n",
       "      <td>0</td>\n",
       "      <td>10249.0</td>\n",
       "      <td>264.7</td>\n",
       "      <td>-264.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>2.16986</td>\n",
       "      <td>0.072573</td>\n",
       "      <td>-0.072573</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-24 15:58:33</td>\n",
       "      <td>2024-09-09 10:08:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1001.01</td>\n",
       "      <td>88863718</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>08h10m19.31s</td>\n",
       "      <td>122.580465</td>\n",
       "      <td>-05d30m49.87s</td>\n",
       "      <td>-5.513852</td>\n",
       "      <td>-4.956</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.555</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.459988e+06</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>-0.001916</td>\n",
       "      <td>0</td>\n",
       "      <td>1.931646</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>3.16600</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>-0.647000</td>\n",
       "      <td>0</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1186.490000</td>\n",
       "      <td>-1186.490000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.215400</td>\n",
       "      <td>2.624200</td>\n",
       "      <td>-2.624200</td>\n",
       "      <td>0</td>\n",
       "      <td>44464.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4045.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.423440</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0</td>\n",
       "      <td>295.862</td>\n",
       "      <td>5.9100</td>\n",
       "      <td>-5.9100</td>\n",
       "      <td>0</td>\n",
       "      <td>7070.0</td>\n",
       "      <td>126.4</td>\n",
       "      <td>-126.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0</td>\n",
       "      <td>2.01000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-24 15:58:33</td>\n",
       "      <td>2023-04-03 14:31:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1002.01</td>\n",
       "      <td>124709665</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>06h58m54.47s</td>\n",
       "      <td>104.726966</td>\n",
       "      <td>-10d34m49.64s</td>\n",
       "      <td>-10.580455</td>\n",
       "      <td>-1.462</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.249</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.459225e+06</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>0</td>\n",
       "      <td>1.867557</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0</td>\n",
       "      <td>1.40800</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>-0.184000</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1.758400</td>\n",
       "      <td>-1.758400</td>\n",
       "      <td>0</td>\n",
       "      <td>23.752900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2860.610000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2037.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.299501</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0</td>\n",
       "      <td>943.109</td>\n",
       "      <td>106.3330</td>\n",
       "      <td>-106.3330</td>\n",
       "      <td>0</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.73000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-24 15:58:33</td>\n",
       "      <td>2022-07-11 16:02:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1003.01</td>\n",
       "      <td>106997505</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>07h22m14.39s</td>\n",
       "      <td>110.559945</td>\n",
       "      <td>-25d12m25.26s</td>\n",
       "      <td>-25.207017</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.640</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.458493e+06</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0</td>\n",
       "      <td>2.743230</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-0.001080</td>\n",
       "      <td>0</td>\n",
       "      <td>3.16700</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>-0.642000</td>\n",
       "      <td>0</td>\n",
       "      <td>383.410000</td>\n",
       "      <td>0.781988</td>\n",
       "      <td>-0.781988</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1177.360000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1631.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.300300</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0</td>\n",
       "      <td>7728.170</td>\n",
       "      <td>1899.5700</td>\n",
       "      <td>-1899.5700</td>\n",
       "      <td>0</td>\n",
       "      <td>5388.5</td>\n",
       "      <td>567.0</td>\n",
       "      <td>-567.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>1.64</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-24 15:58:33</td>\n",
       "      <td>2022-02-23 10:10:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1004.01</td>\n",
       "      <td>238597883</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>08h08m42.77s</td>\n",
       "      <td>122.178195</td>\n",
       "      <td>-48d48m10.12s</td>\n",
       "      <td>-48.802811</td>\n",
       "      <td>-4.496</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.347</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.459987e+06</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>-0.003748</td>\n",
       "      <td>0</td>\n",
       "      <td>3.573014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0</td>\n",
       "      <td>3.37000</td>\n",
       "      <td>1.029000</td>\n",
       "      <td>-1.029000</td>\n",
       "      <td>0</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>1306.550000</td>\n",
       "      <td>-1306.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.311300</td>\n",
       "      <td>3.247140</td>\n",
       "      <td>-3.247140</td>\n",
       "      <td>0</td>\n",
       "      <td>54679.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4260.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.135500</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0</td>\n",
       "      <td>356.437</td>\n",
       "      <td>4.6175</td>\n",
       "      <td>-4.6175</td>\n",
       "      <td>0</td>\n",
       "      <td>9219.0</td>\n",
       "      <td>171.1</td>\n",
       "      <td>-171.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>2.15000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-24 15:58:33</td>\n",
       "      <td>2024-09-09 10:08:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loc_rowid      toi        tid     tfopwg_disp         rastr          ra  \\\n",
       "0          1  1000.01   50365310  FALSE POSITIVE  07h29m25.85s  112.357708   \n",
       "1          2  1001.01   88863718       CANDIDATE  08h10m19.31s  122.580465   \n",
       "2          3  1002.01  124709665  FALSE POSITIVE  06h58m54.47s  104.726966   \n",
       "3          4  1003.01  106997505  FALSE POSITIVE  07h22m14.39s  110.559945   \n",
       "4          5  1004.01  238597883  FALSE POSITIVE  08h08m42.77s  122.178195   \n",
       "\n",
       "          decstr        dec  st_pmra  st_pmraerr1  st_pmraerr2  st_pmralim  \\\n",
       "0  -12d41m45.46s -12.695960   -5.964        0.085       -0.085         0.0   \n",
       "1  -05d30m49.87s  -5.513852   -4.956        0.102       -0.102         0.0   \n",
       "2  -10d34m49.64s -10.580455   -1.462        0.206       -0.206         0.0   \n",
       "3  -25d12m25.26s -25.207017   -0.939        0.041       -0.041         0.0   \n",
       "4  -48d48m10.12s -48.802811   -4.496        0.069       -0.069         0.0   \n",
       "\n",
       "   st_pmdec  st_pmdecerr1  st_pmdecerr2  st_pmdeclim    pl_tranmid  \\\n",
       "0    -0.076         0.072        -0.072          0.0  2.459230e+06   \n",
       "1   -15.555         0.072        -0.072          0.0  2.459988e+06   \n",
       "2    -2.249         0.206        -0.206          0.0  2.459225e+06   \n",
       "3     1.640         0.055        -0.055          0.0  2.458493e+06   \n",
       "4     9.347         0.062        -0.062          0.0  2.459987e+06   \n",
       "\n",
       "   pl_tranmiderr1  pl_tranmiderr2  pl_tranmidlim  pl_orbper  pl_orbpererr1  \\\n",
       "0        0.001657       -0.001657              0   2.171348       0.000264   \n",
       "1        0.001916       -0.001916              0   1.931646       0.000005   \n",
       "2        0.000625       -0.000625              0   1.867557       0.000003   \n",
       "3        0.005350       -0.005350              0   2.743230       0.001080   \n",
       "4        0.003748       -0.003748              0   3.573014       0.000013   \n",
       "\n",
       "   pl_orbpererr2  pl_orbperlim  pl_trandurh  pl_trandurherr1  pl_trandurherr2  \\\n",
       "0      -0.000264             0      2.01722         0.319588        -0.319588   \n",
       "1      -0.000005             0      3.16600         0.647000        -0.647000   \n",
       "2      -0.000003             0      1.40800         0.184000        -0.184000   \n",
       "3      -0.001080             0      3.16700         0.642000        -0.642000   \n",
       "4      -0.000013             0      3.37000         1.029000        -1.029000   \n",
       "\n",
       "   pl_trandurhlim   pl_trandep  pl_trandeperr1  pl_trandeperr2  pl_trandeplim  \\\n",
       "0               0   656.886099       37.778210      -37.778210              0   \n",
       "1               0  1286.000000     1186.490000    -1186.490000              0   \n",
       "2               0  1500.000000        1.758400       -1.758400              0   \n",
       "3               0   383.410000        0.781988       -0.781988              0   \n",
       "4               0   755.000000     1306.550000    -1306.550000              0   \n",
       "\n",
       "     pl_rade  pl_radeerr1  pl_radeerr2  pl_radelim      pl_insol  \\\n",
       "0   5.818163     1.910546    -1.910546           0  22601.948581   \n",
       "1  11.215400     2.624200    -2.624200           0  44464.500000   \n",
       "2  23.752900          NaN          NaN           0   2860.610000   \n",
       "3        NaN          NaN          NaN           0   1177.360000   \n",
       "4  11.311300     3.247140    -3.247140           0  54679.300000   \n",
       "\n",
       "   pl_insolerr1  pl_insolerr2  pl_insollim       pl_eqt  pl_eqterr1  \\\n",
       "0           NaN           NaN          NaN  3127.204052         NaN   \n",
       "1           NaN           NaN          NaN  4045.000000         NaN   \n",
       "2           NaN           NaN          NaN  2037.000000         NaN   \n",
       "3           NaN           NaN          NaN  1631.000000         NaN   \n",
       "4           NaN           NaN          NaN  4260.000000         NaN   \n",
       "\n",
       "   pl_eqterr2  pl_eqtlim   st_tmag  st_tmagerr1  st_tmagerr2  st_tmaglim  \\\n",
       "0         NaN        NaN  9.604000        0.013       -0.013           0   \n",
       "1         NaN        NaN  9.423440        0.006       -0.006           0   \n",
       "2         NaN        NaN  9.299501        0.058       -0.058           0   \n",
       "3         NaN        NaN  9.300300        0.037       -0.037           0   \n",
       "4         NaN        NaN  9.135500        0.006       -0.006           0   \n",
       "\n",
       "    st_dist  st_disterr1  st_disterr2  st_distlim  st_teff  st_tefferr1  \\\n",
       "0   485.735      11.9515     -11.9515           0  10249.0        264.7   \n",
       "1   295.862       5.9100      -5.9100           0   7070.0        126.4   \n",
       "2   943.109     106.3330    -106.3330           0   8924.0        124.0   \n",
       "3  7728.170    1899.5700   -1899.5700           0   5388.5        567.0   \n",
       "4   356.437       4.6175      -4.6175           0   9219.0        171.1   \n",
       "\n",
       "   st_tefferr2  st_tefflim  st_logg  st_loggerr1  st_loggerr2  st_logglim  \\\n",
       "0       -264.7           0     4.19         0.07        -0.07           0   \n",
       "1       -126.4           0     4.03         0.09        -0.09           0   \n",
       "2       -124.0           0      NaN          NaN          NaN           0   \n",
       "3       -567.0           0     4.15         1.64        -1.64           0   \n",
       "4       -171.1           0     4.14         0.07        -0.07           0   \n",
       "\n",
       "    st_rad  st_raderr1  st_raderr2  st_radlim          toi_created  \\\n",
       "0  2.16986    0.072573   -0.072573          0  2019-07-24 15:58:33   \n",
       "1  2.01000    0.090000   -0.090000          0  2019-07-24 15:58:33   \n",
       "2  5.73000         NaN         NaN          0  2019-07-24 15:58:33   \n",
       "3      NaN         NaN         NaN          0  2019-07-24 15:58:33   \n",
       "4  2.15000    0.060000   -0.060000          0  2019-07-24 15:58:33   \n",
       "\n",
       "             rowupdate  \n",
       "0  2024-09-09 10:08:01  \n",
       "1  2023-04-03 14:31:04  \n",
       "2  2022-07-11 16:02:02  \n",
       "3  2022-02-23 10:10:02  \n",
       "4  2024-09-09 10:08:01  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data_filtered/TOI_2025.10.03_08.53.59.csv')\n",
    "print(df.shape)\n",
    "df = df[df[\"tfopwg_disp\"].isin([\"PC\", \"FP\", \"CP\"])]\n",
    "df[\"tfopwg_disp\"] = df[\"tfopwg_disp\"].replace({\n",
    "    \"PC\": \"CANDIDATE\",\n",
    "    \"FP\": \"FALSE POSITIVE\",\n",
    "    \"CP\": \"CONFIRMED\",\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da5c7b8a-4a70-4e12-8e2f-7a916807f627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df[0:100]\n",
    "df2.to_csv('./tess.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a0e762e-b11f-47c8-85db-7259c5fd9b63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfopwg_disp\n",
       "CANDIDATE         4679\n",
       "FALSE POSITIVE    1197\n",
       "CONFIRMED          684\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tfopwg_disp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e7f139-7172-443d-8b76-fa9a6e687f39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6560 entries, 0 to 7702\n",
      "Data columns (total 66 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   loc_rowid        6560 non-null   int64  \n",
      " 1   toi              6560 non-null   float64\n",
      " 2   tid              6560 non-null   int64  \n",
      " 3   tfopwg_disp      6560 non-null   object \n",
      " 4   rastr            6560 non-null   object \n",
      " 5   ra               6560 non-null   float64\n",
      " 6   decstr           6560 non-null   object \n",
      " 7   dec              6560 non-null   float64\n",
      " 8   st_pmra          6446 non-null   float64\n",
      " 9   st_pmraerr1      6446 non-null   float64\n",
      " 10  st_pmraerr2      6446 non-null   float64\n",
      " 11  st_pmralim       6446 non-null   float64\n",
      " 12  st_pmdec         6446 non-null   float64\n",
      " 13  st_pmdecerr1     6446 non-null   float64\n",
      " 14  st_pmdecerr2     6446 non-null   float64\n",
      " 15  st_pmdeclim      6446 non-null   float64\n",
      " 16  pl_tranmid       6560 non-null   float64\n",
      " 17  pl_tranmiderr1   6550 non-null   float64\n",
      " 18  pl_tranmiderr2   6550 non-null   float64\n",
      " 19  pl_tranmidlim    6560 non-null   int64  \n",
      " 20  pl_orbper        6471 non-null   float64\n",
      " 21  pl_orbpererr1    6451 non-null   float64\n",
      " 22  pl_orbpererr2    6451 non-null   float64\n",
      " 23  pl_orbperlim     6560 non-null   int64  \n",
      " 24  pl_trandurh      6560 non-null   float64\n",
      " 25  pl_trandurherr1  6551 non-null   float64\n",
      " 26  pl_trandurherr2  6551 non-null   float64\n",
      " 27  pl_trandurhlim   6560 non-null   int64  \n",
      " 28  pl_trandep       6560 non-null   float64\n",
      " 29  pl_trandeperr1   6556 non-null   float64\n",
      " 30  pl_trandeperr2   6556 non-null   float64\n",
      " 31  pl_trandeplim    6560 non-null   int64  \n",
      " 32  pl_rade          6108 non-null   float64\n",
      " 33  pl_radeerr1      5079 non-null   float64\n",
      " 34  pl_radeerr2      5079 non-null   float64\n",
      " 35  pl_radelim       6560 non-null   int64  \n",
      " 36  pl_insol         6402 non-null   float64\n",
      " 37  pl_insolerr1     0 non-null      float64\n",
      " 38  pl_insolerr2     0 non-null      float64\n",
      " 39  pl_insollim      0 non-null      float64\n",
      " 40  pl_eqt           6302 non-null   float64\n",
      " 41  pl_eqterr1       0 non-null      float64\n",
      " 42  pl_eqterr2       0 non-null      float64\n",
      " 43  pl_eqtlim        0 non-null      float64\n",
      " 44  st_tmag          6560 non-null   float64\n",
      " 45  st_tmagerr1      6560 non-null   float64\n",
      " 46  st_tmagerr2      6560 non-null   float64\n",
      " 47  st_tmaglim       6560 non-null   int64  \n",
      " 48  st_dist          6386 non-null   float64\n",
      " 49  st_disterr1      5970 non-null   float64\n",
      " 50  st_disterr2      5970 non-null   float64\n",
      " 51  st_distlim       6560 non-null   int64  \n",
      " 52  st_teff          6412 non-null   float64\n",
      " 53  st_tefferr1      6251 non-null   float64\n",
      " 54  st_tefferr2      6251 non-null   float64\n",
      " 55  st_tefflim       6560 non-null   int64  \n",
      " 56  st_logg          5805 non-null   float64\n",
      " 57  st_loggerr1      4651 non-null   float64\n",
      " 58  st_loggerr2      4651 non-null   float64\n",
      " 59  st_logglim       6560 non-null   int64  \n",
      " 60  st_rad           6107 non-null   float64\n",
      " 61  st_raderr1       4853 non-null   float64\n",
      " 62  st_raderr2       4853 non-null   float64\n",
      " 63  st_radlim        6560 non-null   int64  \n",
      " 64  toi_created      6560 non-null   object \n",
      " 65  rowupdate        6560 non-null   object \n",
      "dtypes: float64(49), int64(12), object(5)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2119ee61-5d33-4dce-a244-8feb1a265217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.drop(['loc_rowid','tid','toi','rastr','decstr','pl_insolerr1','pl_insolerr2',\n",
    "#          'pl_insollim','pl_eqterr1','pl_eqterr2','pl_eqtlim','toi_created',\n",
    "#          'rowupdate',\n",
    "# \"st_logglim\",\n",
    "# \"st_pmralim\",\n",
    "# \"st_tefflim\",\n",
    "# \"pl_radelim\",\n",
    "# \"pl_trandeplim\",\n",
    "# \"st_pmdeclim\",\n",
    "# \"st_distlim\",\n",
    "# \"pl_tranmidlim\",\n",
    "# \"pl_orbperlim\",\n",
    "# \"pl_trandurhlim\",\n",
    "# \"st_tmaglim\",\n",
    "# \"st_tmagerr2\",\n",
    "# \"st_radlim\"\n",
    "# ],axis=1,inplace=True)\n",
    "\n",
    "df.drop(['loc_rowid','tid','toi','rastr','decstr','pl_insolerr1','pl_insolerr2',\n",
    "         'pl_insollim','pl_eqterr1','pl_eqterr2','pl_eqtlim','toi_created',\n",
    "         'rowupdate'\n",
    "],axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a9442f-a678-40fe-96c3-cba8a0a4c7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>st_pmra</th>\n",
       "      <th>st_pmraerr1</th>\n",
       "      <th>st_pmraerr2</th>\n",
       "      <th>st_pmralim</th>\n",
       "      <th>st_pmdec</th>\n",
       "      <th>st_pmdecerr1</th>\n",
       "      <th>st_pmdecerr2</th>\n",
       "      <th>st_pmdeclim</th>\n",
       "      <th>pl_tranmid</th>\n",
       "      <th>pl_tranmiderr1</th>\n",
       "      <th>pl_tranmiderr2</th>\n",
       "      <th>pl_tranmidlim</th>\n",
       "      <th>pl_orbper</th>\n",
       "      <th>pl_orbpererr1</th>\n",
       "      <th>pl_orbpererr2</th>\n",
       "      <th>pl_orbperlim</th>\n",
       "      <th>pl_trandurh</th>\n",
       "      <th>pl_trandurherr1</th>\n",
       "      <th>pl_trandurherr2</th>\n",
       "      <th>pl_trandurhlim</th>\n",
       "      <th>pl_trandep</th>\n",
       "      <th>pl_trandeperr1</th>\n",
       "      <th>pl_trandeperr2</th>\n",
       "      <th>pl_trandeplim</th>\n",
       "      <th>pl_rade</th>\n",
       "      <th>pl_radeerr1</th>\n",
       "      <th>pl_radeerr2</th>\n",
       "      <th>pl_radelim</th>\n",
       "      <th>pl_insol</th>\n",
       "      <th>pl_eqt</th>\n",
       "      <th>st_tmag</th>\n",
       "      <th>st_tmagerr1</th>\n",
       "      <th>st_tmagerr2</th>\n",
       "      <th>st_tmaglim</th>\n",
       "      <th>st_dist</th>\n",
       "      <th>st_disterr1</th>\n",
       "      <th>st_disterr2</th>\n",
       "      <th>st_distlim</th>\n",
       "      <th>st_teff</th>\n",
       "      <th>st_tefferr1</th>\n",
       "      <th>st_tefferr2</th>\n",
       "      <th>st_tefflim</th>\n",
       "      <th>st_logg</th>\n",
       "      <th>st_loggerr1</th>\n",
       "      <th>st_loggerr2</th>\n",
       "      <th>st_logglim</th>\n",
       "      <th>st_rad</th>\n",
       "      <th>st_raderr1</th>\n",
       "      <th>st_raderr2</th>\n",
       "      <th>st_radlim</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.357708</td>\n",
       "      <td>-12.695960</td>\n",
       "      <td>-5.964</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.459230e+06</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>0</td>\n",
       "      <td>2.171348</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>0</td>\n",
       "      <td>2.01722</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>-0.319588</td>\n",
       "      <td>0</td>\n",
       "      <td>656.886099</td>\n",
       "      <td>37.778210</td>\n",
       "      <td>-37.778210</td>\n",
       "      <td>0</td>\n",
       "      <td>5.818163</td>\n",
       "      <td>1.910546</td>\n",
       "      <td>-1.910546</td>\n",
       "      <td>0</td>\n",
       "      <td>22601.948581</td>\n",
       "      <td>3127.204052</td>\n",
       "      <td>9.604000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0</td>\n",
       "      <td>485.735</td>\n",
       "      <td>11.9515</td>\n",
       "      <td>-11.9515</td>\n",
       "      <td>0</td>\n",
       "      <td>10249.0</td>\n",
       "      <td>264.7</td>\n",
       "      <td>-264.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>2.16986</td>\n",
       "      <td>0.072573</td>\n",
       "      <td>-0.072573</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.580465</td>\n",
       "      <td>-5.513852</td>\n",
       "      <td>-4.956</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.555</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.459988e+06</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>-0.001916</td>\n",
       "      <td>0</td>\n",
       "      <td>1.931646</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>3.16600</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>-0.647000</td>\n",
       "      <td>0</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1186.490000</td>\n",
       "      <td>-1186.490000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.215400</td>\n",
       "      <td>2.624200</td>\n",
       "      <td>-2.624200</td>\n",
       "      <td>0</td>\n",
       "      <td>44464.500000</td>\n",
       "      <td>4045.000000</td>\n",
       "      <td>9.423440</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0</td>\n",
       "      <td>295.862</td>\n",
       "      <td>5.9100</td>\n",
       "      <td>-5.9100</td>\n",
       "      <td>0</td>\n",
       "      <td>7070.0</td>\n",
       "      <td>126.4</td>\n",
       "      <td>-126.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0</td>\n",
       "      <td>2.01000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.726966</td>\n",
       "      <td>-10.580455</td>\n",
       "      <td>-1.462</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.249</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.459225e+06</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>0</td>\n",
       "      <td>1.867557</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0</td>\n",
       "      <td>1.40800</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>-0.184000</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1.758400</td>\n",
       "      <td>-1.758400</td>\n",
       "      <td>0</td>\n",
       "      <td>23.752900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2860.610000</td>\n",
       "      <td>2037.000000</td>\n",
       "      <td>9.299501</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0</td>\n",
       "      <td>943.109</td>\n",
       "      <td>106.3330</td>\n",
       "      <td>-106.3330</td>\n",
       "      <td>0</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.73000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110.559945</td>\n",
       "      <td>-25.207017</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.640</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.458493e+06</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0</td>\n",
       "      <td>2.743230</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-0.001080</td>\n",
       "      <td>0</td>\n",
       "      <td>3.16700</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>-0.642000</td>\n",
       "      <td>0</td>\n",
       "      <td>383.410000</td>\n",
       "      <td>0.781988</td>\n",
       "      <td>-0.781988</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1177.360000</td>\n",
       "      <td>1631.000000</td>\n",
       "      <td>9.300300</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0</td>\n",
       "      <td>7728.170</td>\n",
       "      <td>1899.5700</td>\n",
       "      <td>-1899.5700</td>\n",
       "      <td>0</td>\n",
       "      <td>5388.5</td>\n",
       "      <td>567.0</td>\n",
       "      <td>-567.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>1.64</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122.178195</td>\n",
       "      <td>-48.802811</td>\n",
       "      <td>-4.496</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.347</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.459987e+06</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>-0.003748</td>\n",
       "      <td>0</td>\n",
       "      <td>3.573014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0</td>\n",
       "      <td>3.37000</td>\n",
       "      <td>1.029000</td>\n",
       "      <td>-1.029000</td>\n",
       "      <td>0</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>1306.550000</td>\n",
       "      <td>-1306.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.311300</td>\n",
       "      <td>3.247140</td>\n",
       "      <td>-3.247140</td>\n",
       "      <td>0</td>\n",
       "      <td>54679.300000</td>\n",
       "      <td>4260.000000</td>\n",
       "      <td>9.135500</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0</td>\n",
       "      <td>356.437</td>\n",
       "      <td>4.6175</td>\n",
       "      <td>-4.6175</td>\n",
       "      <td>0</td>\n",
       "      <td>9219.0</td>\n",
       "      <td>171.1</td>\n",
       "      <td>-171.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>2.15000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ra        dec  st_pmra  st_pmraerr1  st_pmraerr2  st_pmralim  \\\n",
       "0  112.357708 -12.695960   -5.964        0.085       -0.085         0.0   \n",
       "1  122.580465  -5.513852   -4.956        0.102       -0.102         0.0   \n",
       "2  104.726966 -10.580455   -1.462        0.206       -0.206         0.0   \n",
       "3  110.559945 -25.207017   -0.939        0.041       -0.041         0.0   \n",
       "4  122.178195 -48.802811   -4.496        0.069       -0.069         0.0   \n",
       "\n",
       "   st_pmdec  st_pmdecerr1  st_pmdecerr2  st_pmdeclim    pl_tranmid  \\\n",
       "0    -0.076         0.072        -0.072          0.0  2.459230e+06   \n",
       "1   -15.555         0.072        -0.072          0.0  2.459988e+06   \n",
       "2    -2.249         0.206        -0.206          0.0  2.459225e+06   \n",
       "3     1.640         0.055        -0.055          0.0  2.458493e+06   \n",
       "4     9.347         0.062        -0.062          0.0  2.459987e+06   \n",
       "\n",
       "   pl_tranmiderr1  pl_tranmiderr2  pl_tranmidlim  pl_orbper  pl_orbpererr1  \\\n",
       "0        0.001657       -0.001657              0   2.171348       0.000264   \n",
       "1        0.001916       -0.001916              0   1.931646       0.000005   \n",
       "2        0.000625       -0.000625              0   1.867557       0.000003   \n",
       "3        0.005350       -0.005350              0   2.743230       0.001080   \n",
       "4        0.003748       -0.003748              0   3.573014       0.000013   \n",
       "\n",
       "   pl_orbpererr2  pl_orbperlim  pl_trandurh  pl_trandurherr1  pl_trandurherr2  \\\n",
       "0      -0.000264             0      2.01722         0.319588        -0.319588   \n",
       "1      -0.000005             0      3.16600         0.647000        -0.647000   \n",
       "2      -0.000003             0      1.40800         0.184000        -0.184000   \n",
       "3      -0.001080             0      3.16700         0.642000        -0.642000   \n",
       "4      -0.000013             0      3.37000         1.029000        -1.029000   \n",
       "\n",
       "   pl_trandurhlim   pl_trandep  pl_trandeperr1  pl_trandeperr2  pl_trandeplim  \\\n",
       "0               0   656.886099       37.778210      -37.778210              0   \n",
       "1               0  1286.000000     1186.490000    -1186.490000              0   \n",
       "2               0  1500.000000        1.758400       -1.758400              0   \n",
       "3               0   383.410000        0.781988       -0.781988              0   \n",
       "4               0   755.000000     1306.550000    -1306.550000              0   \n",
       "\n",
       "     pl_rade  pl_radeerr1  pl_radeerr2  pl_radelim      pl_insol       pl_eqt  \\\n",
       "0   5.818163     1.910546    -1.910546           0  22601.948581  3127.204052   \n",
       "1  11.215400     2.624200    -2.624200           0  44464.500000  4045.000000   \n",
       "2  23.752900          NaN          NaN           0   2860.610000  2037.000000   \n",
       "3        NaN          NaN          NaN           0   1177.360000  1631.000000   \n",
       "4  11.311300     3.247140    -3.247140           0  54679.300000  4260.000000   \n",
       "\n",
       "    st_tmag  st_tmagerr1  st_tmagerr2  st_tmaglim   st_dist  st_disterr1  \\\n",
       "0  9.604000        0.013       -0.013           0   485.735      11.9515   \n",
       "1  9.423440        0.006       -0.006           0   295.862       5.9100   \n",
       "2  9.299501        0.058       -0.058           0   943.109     106.3330   \n",
       "3  9.300300        0.037       -0.037           0  7728.170    1899.5700   \n",
       "4  9.135500        0.006       -0.006           0   356.437       4.6175   \n",
       "\n",
       "   st_disterr2  st_distlim  st_teff  st_tefferr1  st_tefferr2  st_tefflim  \\\n",
       "0     -11.9515           0  10249.0        264.7       -264.7           0   \n",
       "1      -5.9100           0   7070.0        126.4       -126.4           0   \n",
       "2    -106.3330           0   8924.0        124.0       -124.0           0   \n",
       "3   -1899.5700           0   5388.5        567.0       -567.0           0   \n",
       "4      -4.6175           0   9219.0        171.1       -171.1           0   \n",
       "\n",
       "   st_logg  st_loggerr1  st_loggerr2  st_logglim   st_rad  st_raderr1  \\\n",
       "0     4.19         0.07        -0.07           0  2.16986    0.072573   \n",
       "1     4.03         0.09        -0.09           0  2.01000    0.090000   \n",
       "2      NaN          NaN          NaN           0  5.73000         NaN   \n",
       "3     4.15         1.64        -1.64           0      NaN         NaN   \n",
       "4     4.14         0.07        -0.07           0  2.15000    0.060000   \n",
       "\n",
       "   st_raderr2  st_radlim  label  \n",
       "0   -0.072573          0      2  \n",
       "1   -0.090000          0      0  \n",
       "2         NaN          0      2  \n",
       "3         NaN          0      2  \n",
       "4   -0.060000          0      2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Aplicar no label\n",
    "df[\"label\"] = encoder.fit_transform(df[\"tfopwg_disp\"])\n",
    "encoder = LabelEncoder()\n",
    "df.drop(['tfopwg_disp'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32494249-dcb2-447f-b4c7-7c314d846192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6560 entries, 0 to 7702\n",
      "Data columns (total 53 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ra               6560 non-null   float64\n",
      " 1   dec              6560 non-null   float64\n",
      " 2   st_pmra          6446 non-null   float64\n",
      " 3   st_pmraerr1      6446 non-null   float64\n",
      " 4   st_pmraerr2      6446 non-null   float64\n",
      " 5   st_pmralim       6446 non-null   float64\n",
      " 6   st_pmdec         6446 non-null   float64\n",
      " 7   st_pmdecerr1     6446 non-null   float64\n",
      " 8   st_pmdecerr2     6446 non-null   float64\n",
      " 9   st_pmdeclim      6446 non-null   float64\n",
      " 10  pl_tranmid       6560 non-null   float64\n",
      " 11  pl_tranmiderr1   6550 non-null   float64\n",
      " 12  pl_tranmiderr2   6550 non-null   float64\n",
      " 13  pl_tranmidlim    6560 non-null   int64  \n",
      " 14  pl_orbper        6471 non-null   float64\n",
      " 15  pl_orbpererr1    6451 non-null   float64\n",
      " 16  pl_orbpererr2    6451 non-null   float64\n",
      " 17  pl_orbperlim     6560 non-null   int64  \n",
      " 18  pl_trandurh      6560 non-null   float64\n",
      " 19  pl_trandurherr1  6551 non-null   float64\n",
      " 20  pl_trandurherr2  6551 non-null   float64\n",
      " 21  pl_trandurhlim   6560 non-null   int64  \n",
      " 22  pl_trandep       6560 non-null   float64\n",
      " 23  pl_trandeperr1   6556 non-null   float64\n",
      " 24  pl_trandeperr2   6556 non-null   float64\n",
      " 25  pl_trandeplim    6560 non-null   int64  \n",
      " 26  pl_rade          6108 non-null   float64\n",
      " 27  pl_radeerr1      5079 non-null   float64\n",
      " 28  pl_radeerr2      5079 non-null   float64\n",
      " 29  pl_radelim       6560 non-null   int64  \n",
      " 30  pl_insol         6402 non-null   float64\n",
      " 31  pl_eqt           6302 non-null   float64\n",
      " 32  st_tmag          6560 non-null   float64\n",
      " 33  st_tmagerr1      6560 non-null   float64\n",
      " 34  st_tmagerr2      6560 non-null   float64\n",
      " 35  st_tmaglim       6560 non-null   int64  \n",
      " 36  st_dist          6386 non-null   float64\n",
      " 37  st_disterr1      5970 non-null   float64\n",
      " 38  st_disterr2      5970 non-null   float64\n",
      " 39  st_distlim       6560 non-null   int64  \n",
      " 40  st_teff          6412 non-null   float64\n",
      " 41  st_tefferr1      6251 non-null   float64\n",
      " 42  st_tefferr2      6251 non-null   float64\n",
      " 43  st_tefflim       6560 non-null   int64  \n",
      " 44  st_logg          5805 non-null   float64\n",
      " 45  st_loggerr1      4651 non-null   float64\n",
      " 46  st_loggerr2      4651 non-null   float64\n",
      " 47  st_logglim       6560 non-null   int64  \n",
      " 48  st_rad           6107 non-null   float64\n",
      " 49  st_raderr1       4853 non-null   float64\n",
      " 50  st_raderr2       4853 non-null   float64\n",
      " 51  st_radlim        6560 non-null   int64  \n",
      " 52  label            6560 non-null   int64  \n",
      "dtypes: float64(42), int64(11)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dec5addc-8bc9-461f-93e4-795e6bfef8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6560 entries, 0 to 7702\n",
      "Data columns (total 53 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ra               6560 non-null   float64\n",
      " 1   dec              6560 non-null   float64\n",
      " 2   st_pmra          6560 non-null   float64\n",
      " 3   st_pmraerr1      6560 non-null   float64\n",
      " 4   st_pmraerr2      6560 non-null   float64\n",
      " 5   st_pmralim       6560 non-null   float64\n",
      " 6   st_pmdec         6560 non-null   float64\n",
      " 7   st_pmdecerr1     6560 non-null   float64\n",
      " 8   st_pmdecerr2     6560 non-null   float64\n",
      " 9   st_pmdeclim      6560 non-null   float64\n",
      " 10  pl_tranmid       6560 non-null   float64\n",
      " 11  pl_tranmiderr1   6560 non-null   float64\n",
      " 12  pl_tranmiderr2   6560 non-null   float64\n",
      " 13  pl_tranmidlim    6560 non-null   int64  \n",
      " 14  pl_orbper        6560 non-null   float64\n",
      " 15  pl_orbpererr1    6560 non-null   float64\n",
      " 16  pl_orbpererr2    6560 non-null   float64\n",
      " 17  pl_orbperlim     6560 non-null   int64  \n",
      " 18  pl_trandurh      6560 non-null   float64\n",
      " 19  pl_trandurherr1  6560 non-null   float64\n",
      " 20  pl_trandurherr2  6560 non-null   float64\n",
      " 21  pl_trandurhlim   6560 non-null   int64  \n",
      " 22  pl_trandep       6560 non-null   float64\n",
      " 23  pl_trandeperr1   6560 non-null   float64\n",
      " 24  pl_trandeperr2   6560 non-null   float64\n",
      " 25  pl_trandeplim    6560 non-null   int64  \n",
      " 26  pl_rade          6560 non-null   float64\n",
      " 27  pl_radeerr1      6560 non-null   float64\n",
      " 28  pl_radeerr2      6560 non-null   float64\n",
      " 29  pl_radelim       6560 non-null   int64  \n",
      " 30  pl_insol         6560 non-null   float64\n",
      " 31  pl_eqt           6560 non-null   float64\n",
      " 32  st_tmag          6560 non-null   float64\n",
      " 33  st_tmagerr1      6560 non-null   float64\n",
      " 34  st_tmagerr2      6560 non-null   float64\n",
      " 35  st_tmaglim       6560 non-null   int64  \n",
      " 36  st_dist          6560 non-null   float64\n",
      " 37  st_disterr1      6560 non-null   float64\n",
      " 38  st_disterr2      6560 non-null   float64\n",
      " 39  st_distlim       6560 non-null   int64  \n",
      " 40  st_teff          6560 non-null   float64\n",
      " 41  st_tefferr1      6560 non-null   float64\n",
      " 42  st_tefferr2      6560 non-null   float64\n",
      " 43  st_tefflim       6560 non-null   int64  \n",
      " 44  st_logg          6560 non-null   float64\n",
      " 45  st_loggerr1      6560 non-null   float64\n",
      " 46  st_loggerr2      6560 non-null   float64\n",
      " 47  st_logglim       6560 non-null   int64  \n",
      " 48  st_rad           6560 non-null   float64\n",
      " 49  st_raderr1       6560 non-null   float64\n",
      " 50  st_raderr2       6560 non-null   float64\n",
      " 51  st_radlim        6560 non-null   int64  \n",
      " 52  label            6560 non-null   int64  \n",
      "dtypes: float64(42), int64(11)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(df.mean())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "068f4989-5707-499d-bdad-fa08f2065aab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4679\n",
       "2    1197\n",
       "1     684\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6ded05-39f4-4dfc-95cf-c6dda31cf8e0",
   "metadata": {},
   "source": [
    "## Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1586002-f1cc-47bd-99e5-1479c77725e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df[[\n",
    "    \"st_dist\",\n",
    "    \"st_tmag\",\n",
    "    \"pl_eqt\",\n",
    "    \"pl_insol\",\n",
    "    \"st_disterr2\",\n",
    "    \"st_disterr1\",\n",
    "    \"pl_rade\",\n",
    "    \"pl_tranmid\",\n",
    "    \"pl_tranmiderr2\",\n",
    "    \"st_raderr2\", \"label\"\n",
    "]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ecd2a39-ed73-4e83-b54b-572480e3ce58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6560 entries, 0 to 7702\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   st_dist         6560 non-null   float64\n",
      " 1   st_tmag         6560 non-null   float64\n",
      " 2   pl_eqt          6560 non-null   float64\n",
      " 3   pl_insol        6560 non-null   float64\n",
      " 4   st_disterr2     6560 non-null   float64\n",
      " 5   st_disterr1     6560 non-null   float64\n",
      " 6   pl_rade         6560 non-null   float64\n",
      " 7   pl_tranmid      6560 non-null   float64\n",
      " 8   pl_tranmiderr2  6560 non-null   float64\n",
      " 9   st_raderr2      6560 non-null   float64\n",
      " 10  label           6560 non-null   int64  \n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 615.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b15d60b-524a-4f68-9ae5-74727d172def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4592, 10)\n",
      "Test shape: (1312, 10)\n",
      "Blind validation shape: (656, 10)\n",
      "\n",
      "Fold 1\n",
      "Validation Accuracy: 0.7617 | F1-score: 0.7473\n",
      "\n",
      "Fold 2\n",
      "Validation Accuracy: 0.7769 | F1-score: 0.7645\n",
      "\n",
      "Fold 3\n",
      "Validation Accuracy: 0.7767 | F1-score: 0.7643\n",
      "\n",
      "Fold 4\n",
      "Validation Accuracy: 0.7680 | F1-score: 0.7567\n",
      "\n",
      "Fold 5\n",
      "Validation Accuracy: 0.7821 | F1-score: 0.7674\n",
      "\n",
      "Mdia Validation Accuracy: 0.7731\n",
      "Mdia Validation F1-score: 0.7600\n",
      "\n",
      "Top 10 Feature importances:\n",
      "st_disterr1       0.231626\n",
      "st_tmag           0.111663\n",
      "pl_insol          0.106755\n",
      "st_dist           0.093417\n",
      "pl_eqt            0.083912\n",
      "pl_rade           0.083599\n",
      "pl_tranmid        0.082880\n",
      "st_disterr2       0.076727\n",
      "pl_tranmiderr2    0.068754\n",
      "st_raderr2        0.060667\n",
      "dtype: float32\n",
      "\n",
      "--- Base Model Test Results ---\n",
      "Accuracy: 0.7759\n",
      "F1-score: 0.7601\n",
      "\n",
      "--- Base Model Blind Results ---\n",
      "Accuracy: 0.7835\n",
      "F1-score: 0.7657\n",
      "0.9 ['st_disterr1', 'st_tmag', 'pl_insol', 'st_dist', 'pl_eqt', 'pl_rade', 'pl_tranmid', 'st_disterr2']\n",
      "\n",
      "===== Testing with top 90% feature importance =====\n",
      "Selected features: 8\n",
      "Test Accuracy: 0.7683 | F1: 0.7517\n",
      "Blind Accuracy: 0.7820 | F1: 0.7652\n",
      "\n",
      " Number of Features for this model: 8\n",
      "\n",
      " Classification Test Report: TESS (TOI) Light Model with 90% feature importance\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       936\n",
      "           1       0.54      0.41      0.46       137\n",
      "           2       0.64      0.41      0.50       239\n",
      "\n",
      "    accuracy                           0.77      1312\n",
      "   macro avg       0.66      0.58      0.61      1312\n",
      "weighted avg       0.75      0.77      0.75      1312\n",
      "\n",
      "\n",
      " Classification Blind Report: TESS (TOI) Light Model with 90% feature importance\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       468\n",
      "           1       0.67      0.38      0.49        68\n",
      "           2       0.63      0.46      0.53       120\n",
      "\n",
      "    accuracy                           0.78       656\n",
      "   macro avg       0.70      0.59      0.63       656\n",
      "weighted avg       0.77      0.78      0.77       656\n",
      "\n",
      "0.95 ['st_disterr1', 'st_tmag', 'pl_insol', 'st_dist', 'pl_eqt', 'pl_rade', 'pl_tranmid', 'st_disterr2', 'pl_tranmiderr2']\n",
      "\n",
      "===== Testing with top 95% feature importance =====\n",
      "Selected features: 9\n",
      "Test Accuracy: 0.7668 | F1: 0.7515\n",
      "Blind Accuracy: 0.7683 | F1: 0.7484\n",
      "\n",
      " Number of Features for this model: 9\n",
      "\n",
      " Classification Test Report: TESS (TOI) Light Model with 95% feature importance\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       936\n",
      "           1       0.57      0.42      0.48       137\n",
      "           2       0.64      0.43      0.52       239\n",
      "\n",
      "    accuracy                           0.77      1312\n",
      "   macro avg       0.67      0.58      0.62      1312\n",
      "weighted avg       0.75      0.77      0.75      1312\n",
      "\n",
      "\n",
      " Classification Blind Report: TESS (TOI) Light Model with 95% feature importance\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86       468\n",
      "           1       0.56      0.32      0.41        68\n",
      "           2       0.64      0.43      0.52       120\n",
      "\n",
      "    accuracy                           0.77       656\n",
      "   macro avg       0.67      0.56      0.60       656\n",
      "weighted avg       0.75      0.77      0.75       656\n",
      "\n",
      "0.99 ['st_disterr1', 'st_tmag', 'pl_insol', 'st_dist', 'pl_eqt', 'pl_rade', 'pl_tranmid', 'st_disterr2', 'pl_tranmiderr2']\n",
      "\n",
      "===== Testing with top 99% feature importance =====\n",
      "Selected features: 9\n",
      "Test Accuracy: 0.7668 | F1: 0.7515\n",
      "Blind Accuracy: 0.7683 | F1: 0.7484\n",
      "\n",
      " Number of Features for this model: 9\n",
      "\n",
      " Classification Test Report: TESS (TOI) Light Model with 99% feature importance\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       936\n",
      "           1       0.57      0.42      0.48       137\n",
      "           2       0.64      0.43      0.52       239\n",
      "\n",
      "    accuracy                           0.77      1312\n",
      "   macro avg       0.67      0.58      0.62      1312\n",
      "weighted avg       0.75      0.77      0.75      1312\n",
      "\n",
      "\n",
      " Classification Blind Report: TESS (TOI) Light Model with 99% feature importance\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86       468\n",
      "           1       0.56      0.32      0.41        68\n",
      "           2       0.64      0.43      0.52       120\n",
      "\n",
      "    accuracy                           0.77       656\n",
      "   macro avg       0.67      0.56      0.60       656\n",
      "weighted avg       0.75      0.77      0.75       656\n",
      "\n",
      "\n",
      "=== Summary of Reduced Feature Tests ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:1028: UserWarning: [01:40:56] WARNING: /workspace/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>N_Features</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Blind_Accuracy</th>\n",
       "      <th>Blind_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90%</td>\n",
       "      <td>8</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.751696</td>\n",
       "      <td>0.782012</td>\n",
       "      <td>0.765209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95%</td>\n",
       "      <td>9</td>\n",
       "      <td>0.766768</td>\n",
       "      <td>0.751540</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.748367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99%</td>\n",
       "      <td>9</td>\n",
       "      <td>0.766768</td>\n",
       "      <td>0.751540</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.748367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Threshold  N_Features  Test_Accuracy   Test_F1  Blind_Accuracy  Blind_F1\n",
       "0       90%           8       0.768293  0.751696        0.782012  0.765209\n",
       "1       95%           9       0.766768  0.751540        0.768293  0.748367\n",
       "2       99%           9       0.766768  0.751540        0.768293  0.748367"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total runtime: 4.97 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "start = time()\n",
    "\n",
    "# ==============================\n",
    "# SPLITS E MODELO BASE\n",
    "# ==============================\n",
    "\n",
    "# Features e label\n",
    "X = df_final.drop(['label'], axis=1)\n",
    "y = df_final['label']\n",
    "\n",
    "# Primeiro split: 70% treino, 30% restante\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Segundo split: 20% teste, 10% blind validation\n",
    "X_test, X_blind, y_test, y_blind = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.3333, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train_full.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "print(f\"Blind validation shape: {X_blind.shape}\")\n",
    "\n",
    "# ==============================\n",
    "# CROSS-VALIDATION\n",
    "# ==============================\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full, y_train_full), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
    "    y_train, y_val = y_train_full.iloc[train_idx], y_train_full.iloc[val_idx]\n",
    "\n",
    "    model = xgb.XGBClassifier(eval_metric='mlogloss', objective='multi:softprob')\n",
    "    model.fit(X_train.values, y_train.values)\n",
    "\n",
    "    y_pred_val = model.predict(X_val.values)\n",
    "    acc = accuracy_score(y_val, y_pred_val)\n",
    "    f1 = f1_score(y_val, y_pred_val, average='weighted')\n",
    "    print(f\"Validation Accuracy: {acc:.4f} | F1-score: {f1:.4f}\")\n",
    "    fold_results.append({'fold': fold, 'accuracy': acc, 'f1': f1})\n",
    "\n",
    "acc_mean = np.mean([r['accuracy'] for r in fold_results])\n",
    "f1_mean = np.mean([r['f1'] for r in fold_results])\n",
    "print(f\"\\nMdia Validation Accuracy: {acc_mean:.4f}\")\n",
    "print(f\"Mdia Validation F1-score: {f1_mean:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# MODELO FINAL COMPLETO\n",
    "# ==============================\n",
    "\n",
    "final_model = xgb.XGBClassifier(eval_metric='mlogloss', objective='multi:softprob')\n",
    "final_model.fit(X_train_full.values, y_train_full.values)\n",
    "\n",
    "feat_imp = pd.Series(final_model.feature_importances_, index=X_train_full.columns).sort_values(ascending=False)\n",
    "feat_imp.to_csv('summary/Tess_light_all_feature_importance.csv')\n",
    "print(\"\\nTop 10 Feature importances:\")\n",
    "print(feat_imp.head(10))\n",
    "\n",
    "# Avaliao no teste\n",
    "y_pred_test = final_model.predict(X_test.values)\n",
    "print(\"\\n--- Base Model Test Results ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_test, y_pred_test, average='weighted'):.4f}\")\n",
    "\n",
    "# Avaliao na blind validation\n",
    "y_pred_blind = final_model.predict(X_blind.values)\n",
    "print(\"\\n--- Base Model Blind Results ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_blind, y_pred_blind):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_blind, y_pred_blind, average='weighted'):.4f}\")\n",
    "\n",
    "#joblib.dump(final_model, 'xgb_final_model.pkl')\n",
    "\n",
    "# ==============================\n",
    "# TESTES COM 90%, 95%, 99% DAS FEATURES\n",
    "# ==============================\n",
    "\n",
    "thresholds = [0.90, 0.95, 0.99]\n",
    "results_summary = []\n",
    "\n",
    "feat_imp_cumsum = feat_imp.cumsum()\n",
    "\n",
    "for th in thresholds:\n",
    "    selected_features = feat_imp_cumsum[feat_imp_cumsum <= th].index.tolist()\n",
    "    print(th,selected_features)\n",
    "    print(f\"\\n===== Testing with top {th*100:.0f}% feature importance =====\")\n",
    "    print(f\"Selected features: {len(selected_features)}\")\n",
    "\n",
    "    X_train_sel = X_train_full[selected_features]\n",
    "    X_test_sel = X_test[selected_features]\n",
    "    X_blind_sel = X_blind[selected_features]\n",
    "\n",
    "    model_sel = xgb.XGBClassifier(eval_metric='mlogloss', objective='multi:softprob')\n",
    "    model_sel.fit(X_train_sel.values, y_train_full.values)\n",
    "\n",
    "    # Test set\n",
    "    y_pred_test_sel = model_sel.predict(X_test_sel.values)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test_sel)\n",
    "    f1_test = f1_score(y_test, y_pred_test_sel, average='weighted')\n",
    "\n",
    "    # Blind set\n",
    "    y_pred_blind_sel = model_sel.predict(X_blind_sel.values)\n",
    "    acc_blind = accuracy_score(y_blind, y_pred_blind_sel)\n",
    "    f1_blind = f1_score(y_blind, y_pred_blind_sel, average='weighted')\n",
    "\n",
    "    print(f\"Test Accuracy: {acc_test:.4f} | F1: {f1_test:.4f}\")\n",
    "    print(f\"Blind Accuracy: {acc_blind:.4f} | F1: {f1_blind:.4f}\")\n",
    "    report_test = classification_report(y_test, y_pred_test_sel)\n",
    "    report_blind = classification_report(y_blind, y_pred_blind_sel)\n",
    "    print(f\"\\n Number of Features for this model: {X_test_sel.shape[1]}\")\n",
    "    print(f\"\\n Classification Test Report: TESS (TOI) Light Model with {th*100:.0f}% feature importance\\n\", report_test)\n",
    "    print(f\"\\n Classification Blind Report: TESS (TOI) Light Model with {th*100:.0f}% feature importance\\n\", report_blind)\n",
    "\n",
    "    results_summary.append({\n",
    "        'Threshold': f'{int(th*100)}%',\n",
    "        'N_Features': len(selected_features),\n",
    "        'Test_Accuracy': acc_test,\n",
    "        'Test_F1': f1_test,\n",
    "        'Blind_Accuracy': acc_blind,\n",
    "        'Blind_F1': f1_blind\n",
    "    })\n",
    "\n",
    "    # Salvar modelo em formatos PKL e JSON\n",
    "    #joblib.dump(model_sel, f'xgb_model_{int(th*100)}perc_features.pkl')\n",
    "final_model.save_model(f'models/tess_lite.model')\n",
    "\n",
    "# ==============================\n",
    "# SUMRIO FINAL\n",
    "# ==============================\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(\"\\n=== Summary of Reduced Feature Tests ===\")\n",
    "display(results_df)\n",
    "results_df.to_csv(\"summary/Tess_light_feature_importance_summary.csv\", index=False)\n",
    "\n",
    "end = time()\n",
    "print(f\"\\nTotal runtime: {end - start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfd97463-a699-4294-8a45-943d246f0597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-05 13:25:55,397] A new study created in memory with name: no-name-5643c3cb-2f1b-45c3-8301-cbb7eb042d04\n",
      "[I 2025-10-05 13:25:58,798] Trial 0 finished with value: 0.7704338154522922 and parameters: {'learning_rate': 0.024038403779744606, 'max_depth': 4, 'subsample': 0.9741691852657262, 'colsample_bytree': 0.6927561655886202, 'reg_alpha': 0.937554996896772, 'reg_lambda': 0.195065515844573, 'gamma': 1.4638722648687656, 'n_estimators': 432}. Best is trial 0 with value: 0.7704338154522922.\n",
      "[I 2025-10-05 13:26:07,132] Trial 1 finished with value: 0.7726729848258529 and parameters: {'learning_rate': 0.08062597270281867, 'max_depth': 9, 'subsample': 0.7144118792860741, 'colsample_bytree': 0.6129306707804127, 'reg_alpha': 1.3699328795393788, 'reg_lambda': 0.8101409334080875, 'gamma': 1.4636614114412998, 'n_estimators': 633}. Best is trial 1 with value: 0.7726729848258529.\n",
      "[I 2025-10-05 13:26:09,161] Trial 2 finished with value: 0.7786477503314863 and parameters: {'learning_rate': 0.24137543534054628, 'max_depth': 5, 'subsample': 0.6388846546159486, 'colsample_bytree': 0.6698010538896823, 'reg_alpha': 0.49472749295866447, 'reg_lambda': 0.09325997717626056, 'gamma': 0.7925809907854642, 'n_estimators': 442}. Best is trial 2 with value: 0.7786477503314863.\n",
      "[I 2025-10-05 13:26:13,400] Trial 3 finished with value: 0.7817603671427863 and parameters: {'learning_rate': 0.12087903790910243, 'max_depth': 10, 'subsample': 0.969930506331113, 'colsample_bytree': 0.616272532389367, 'reg_alpha': 0.4962835130998442, 'reg_lambda': 2.6067273660326715, 'gamma': 0.31594755811150343, 'n_estimators': 664}. Best is trial 3 with value: 0.7817603671427863.\n",
      "[I 2025-10-05 13:26:15,672] Trial 4 finished with value: 0.7804542626701794 and parameters: {'learning_rate': 0.15253013829762915, 'max_depth': 9, 'subsample': 0.8259579943873201, 'colsample_bytree': 0.9276357824449456, 'reg_alpha': 0.40545387051331727, 'reg_lambda': 2.266895048882294, 'gamma': 2.713135340212087, 'n_estimators': 693}. Best is trial 3 with value: 0.7817603671427863.\n",
      "[I 2025-10-05 13:26:19,533] Trial 5 finished with value: 0.7705568831099444 and parameters: {'learning_rate': 0.07199456781807101, 'max_depth': 6, 'subsample': 0.948849706284355, 'colsample_bytree': 0.8802456329174357, 'reg_alpha': 1.02967134682221, 'reg_lambda': 0.8666679636776009, 'gamma': 2.877957838484207, 'n_estimators': 751}. Best is trial 3 with value: 0.7817603671427863.\n",
      "[I 2025-10-05 13:26:22,711] Trial 6 finished with value: 0.7753258978167215 and parameters: {'learning_rate': 0.20066017208217007, 'max_depth': 9, 'subsample': 0.6691012382865867, 'colsample_bytree': 0.8569248527036283, 'reg_alpha': 1.3837480014160082, 'reg_lambda': 2.609581783684452, 'gamma': 1.0759858437472054, 'n_estimators': 761}. Best is trial 3 with value: 0.7817603671427863.\n",
      "[I 2025-10-05 13:26:24,240] Trial 7 finished with value: 0.7732476870857984 and parameters: {'learning_rate': 0.19677814717804692, 'max_depth': 8, 'subsample': 0.9879674987710897, 'colsample_bytree': 0.8598628874085419, 'reg_alpha': 0.7882669984466746, 'reg_lambda': 1.4583808231812125, 'gamma': 2.9089631849268365, 'n_estimators': 504}. Best is trial 3 with value: 0.7817603671427863.\n",
      "[I 2025-10-05 13:26:37,657] Trial 8 finished with value: 0.7887738560390508 and parameters: {'learning_rate': 0.02641105904336761, 'max_depth': 10, 'subsample': 0.6396416000559708, 'colsample_bytree': 0.6979651945371516, 'reg_alpha': 1.612590312840389, 'reg_lambda': 1.3628280388792993, 'gamma': 0.5430008414928928, 'n_estimators': 747}. Best is trial 8 with value: 0.7887738560390508.\n",
      "[I 2025-10-05 13:26:39,526] Trial 9 finished with value: 0.7838220416826519 and parameters: {'learning_rate': 0.12889668579065094, 'max_depth': 3, 'subsample': 0.8305894086240264, 'colsample_bytree': 0.7766480313797754, 'reg_alpha': 0.7901665358678005, 'reg_lambda': 1.1455525053663562, 'gamma': 1.9261961626911588, 'n_estimators': 642}. Best is trial 8 with value: 0.7887738560390508.\n",
      "[I 2025-10-05 13:26:44,157] Trial 10 finished with value: 0.7877020813156212 and parameters: {'learning_rate': 0.2881910367907313, 'max_depth': 7, 'subsample': 0.7582328807616235, 'colsample_bytree': 0.9999056670390243, 'reg_alpha': 1.86178322734943, 'reg_lambda': 1.935016943904928, 'gamma': 0.037929785969407326, 'n_estimators': 322}. Best is trial 8 with value: 0.7887738560390508.\n",
      "[I 2025-10-05 13:26:48,919] Trial 11 finished with value: 0.7838553567486574 and parameters: {'learning_rate': 0.2878190333366424, 'max_depth': 7, 'subsample': 0.751682906817238, 'colsample_bytree': 0.9958237810223167, 'reg_alpha': 1.9486971501564272, 'reg_lambda': 1.9117162637254228, 'gamma': 0.030642650896094942, 'n_estimators': 302}. Best is trial 8 with value: 0.7887738560390508.\n",
      "[I 2025-10-05 13:26:51,242] Trial 12 finished with value: 0.785083881054099 and parameters: {'learning_rate': 0.2913304538274408, 'max_depth': 7, 'subsample': 0.6067258872385186, 'colsample_bytree': 0.7561574204305004, 'reg_alpha': 1.9668785281898928, 'reg_lambda': 1.9176494317019483, 'gamma': 0.5402710497191268, 'n_estimators': 301}. Best is trial 8 with value: 0.7887738560390508.\n",
      "[I 2025-10-05 13:27:17,660] Trial 13 finished with value: 0.7835653578953328 and parameters: {'learning_rate': 0.0401200801108102, 'max_depth': 10, 'subsample': 0.7637454014002881, 'colsample_bytree': 0.7159336691045368, 'reg_alpha': 1.5999921488633184, 'reg_lambda': 1.7393706226253611, 'gamma': 0.02428878073660875, 'n_estimators': 567}. Best is trial 8 with value: 0.7887738560390508.\n",
      "[I 2025-10-05 13:27:20,925] Trial 14 finished with value: 0.7844487282482717 and parameters: {'learning_rate': 0.23004741779415666, 'max_depth': 6, 'subsample': 0.8727794010508512, 'colsample_bytree': 0.9965720219296011, 'reg_alpha': 1.638794835412832, 'reg_lambda': 1.3635823651819414, 'gamma': 0.8463008828989542, 'n_estimators': 389}. Best is trial 8 with value: 0.7887738560390508.\n",
      "[I 2025-10-05 13:27:27,344] Trial 15 finished with value: 0.7902130349240313 and parameters: {'learning_rate': 0.0887368905629785, 'max_depth': 8, 'subsample': 0.6901418530744159, 'colsample_bytree': 0.9258106869017253, 'reg_alpha': 1.6932360613207322, 'reg_lambda': 2.1688417328472194, 'gamma': 0.4500124854385549, 'n_estimators': 547}. Best is trial 15 with value: 0.7902130349240313.\n",
      "[I 2025-10-05 13:27:38,593] Trial 16 finished with value: 0.7715771302774916 and parameters: {'learning_rate': 0.010900295293922002, 'max_depth': 8, 'subsample': 0.6810329787235082, 'colsample_bytree': 0.8103065737561462, 'reg_alpha': 1.346744842751126, 'reg_lambda': 2.8473923818399984, 'gamma': 1.858251934069838, 'n_estimators': 561}. Best is trial 15 with value: 0.7902130349240313.\n",
      "[I 2025-10-05 13:27:44,202] Trial 17 finished with value: 0.7782429429677226 and parameters: {'learning_rate': 0.07379854563596801, 'max_depth': 10, 'subsample': 0.6190347312265048, 'colsample_bytree': 0.7346442572449842, 'reg_alpha': 0.02136591010693978, 'reg_lambda': 2.21279493517053, 'gamma': 1.1409046120080442, 'n_estimators': 797}. Best is trial 15 with value: 0.7902130349240313.\n",
      "[I 2025-10-05 13:27:50,074] Trial 18 finished with value: 0.7866502999276547 and parameters: {'learning_rate': 0.10146113304109365, 'max_depth': 8, 'subsample': 0.703167526488843, 'colsample_bytree': 0.9111243706849299, 'reg_alpha': 1.6374622091814408, 'reg_lambda': 0.5843429037925818, 'gamma': 0.4245177484301892, 'n_estimators': 510}. Best is trial 15 with value: 0.7902130349240313.\n",
      "[I 2025-10-05 13:28:00,200] Trial 19 finished with value: 0.7850026529776558 and parameters: {'learning_rate': 0.034845697433301515, 'max_depth': 9, 'subsample': 0.6561059156811077, 'colsample_bytree': 0.8219120127714842, 'reg_alpha': 1.1914280308972993, 'reg_lambda': 1.1998450304529276, 'gamma': 0.7410586746390028, 'n_estimators': 594}. Best is trial 15 with value: 0.7902130349240313.\n",
      "[I 2025-10-05 13:28:08,336] Trial 20 finished with value: 0.7726915029262644 and parameters: {'learning_rate': 0.05781365445859901, 'max_depth': 8, 'subsample': 0.7194379254480673, 'colsample_bytree': 0.6480260603883925, 'reg_alpha': 1.7502395901985128, 'reg_lambda': 1.6271337342813261, 'gamma': 2.310794327878728, 'n_estimators': 707}. Best is trial 15 with value: 0.7902130349240313.\n",
      "[I 2025-10-05 13:28:12,648] Trial 21 finished with value: 0.7873951480401179 and parameters: {'learning_rate': 0.16871900408666174, 'max_depth': 7, 'subsample': 0.7594398470585009, 'colsample_bytree': 0.9427105248217347, 'reg_alpha': 1.8066637609193947, 'reg_lambda': 2.1524324811578195, 'gamma': 0.2611962755243551, 'n_estimators': 364}. Best is trial 15 with value: 0.7902130349240313.\n",
      "[I 2025-10-05 13:28:16,735] Trial 22 finished with value: 0.7799713801932475 and parameters: {'learning_rate': 0.11065828635251886, 'max_depth': 5, 'subsample': 0.8081840078338881, 'colsample_bytree': 0.964595167231309, 'reg_alpha': 1.5102413597042927, 'reg_lambda': 1.9618032223291995, 'gamma': 0.5601155043648636, 'n_estimators': 498}. Best is trial 15 with value: 0.7902130349240313.\n",
      "[I 2025-10-05 13:28:23,288] Trial 23 finished with value: 0.7932243795478454 and parameters: {'learning_rate': 0.14916893969053008, 'max_depth': 6, 'subsample': 0.73162110107907, 'colsample_bytree': 0.9638469371144848, 'reg_alpha': 1.7840138954535165, 'reg_lambda': 2.4789012478298833, 'gamma': 0.20528399661342822, 'n_estimators': 454}. Best is trial 23 with value: 0.7932243795478454.\n",
      "[I 2025-10-05 13:28:26,123] Trial 24 finished with value: 0.7848602588025897 and parameters: {'learning_rate': 0.14206225306271586, 'max_depth': 5, 'subsample': 0.6939517774438487, 'colsample_bytree': 0.89405730194679, 'reg_alpha': 1.4902348689003646, 'reg_lambda': 2.5138949441479412, 'gamma': 1.0369058721147575, 'n_estimators': 455}. Best is trial 23 with value: 0.7932243795478454.\n",
      "[I 2025-10-05 13:28:34,342] Trial 25 finished with value: 0.7937681165351771 and parameters: {'learning_rate': 0.1008931455889113, 'max_depth': 6, 'subsample': 0.6289329866193453, 'colsample_bytree': 0.9589746181603868, 'reg_alpha': 1.1474238315799892, 'reg_lambda': 2.9991596011021215, 'gamma': 0.2367594379070153, 'n_estimators': 601}. Best is trial 25 with value: 0.7937681165351771.\n",
      "[I 2025-10-05 13:28:39,371] Trial 26 finished with value: 0.787703681360541 and parameters: {'learning_rate': 0.17522020188734316, 'max_depth': 6, 'subsample': 0.7352156849224921, 'colsample_bytree': 0.9602297758917984, 'reg_alpha': 1.1574661886101034, 'reg_lambda': 2.7816834797044687, 'gamma': 0.2536923625603573, 'n_estimators': 597}. Best is trial 25 with value: 0.7937681165351771.\n",
      "[I 2025-10-05 13:28:44,769] Trial 27 finished with value: 0.7882071972594442 and parameters: {'learning_rate': 0.09374206181224203, 'max_depth': 4, 'subsample': 0.8807870250214797, 'colsample_bytree': 0.9582181502868936, 'reg_alpha': 1.2389884683679562, 'reg_lambda': 2.9988636726577513, 'gamma': 0.2354236767578613, 'n_estimators': 525}. Best is trial 25 with value: 0.7937681165351771.\n",
      "[I 2025-10-05 13:28:48,601] Trial 28 finished with value: 0.7792703050381731 and parameters: {'learning_rate': 0.1338713575143043, 'max_depth': 6, 'subsample': 0.601017573726399, 'colsample_bytree': 0.9233356587066502, 'reg_alpha': 1.7966863306093601, 'reg_lambda': 2.451469191357454, 'gamma': 0.7212725498975077, 'n_estimators': 474}. Best is trial 25 with value: 0.7937681165351771.\n",
      "[I 2025-10-05 13:28:52,517] Trial 29 finished with value: 0.7863410412388934 and parameters: {'learning_rate': 0.05503921550997487, 'max_depth': 4, 'subsample': 0.6716853855823501, 'colsample_bytree': 0.8348453534232305, 'reg_alpha': 0.9884956241165962, 'reg_lambda': 2.9970759188899763, 'gamma': 0.9874501506413383, 'n_estimators': 415}. Best is trial 25 with value: 0.7937681165351771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1008931455889113, 'max_depth': 6, 'subsample': 0.6289329866193453, 'colsample_bytree': 0.9589746181603868, 'reg_alpha': 1.1474238315799892, 'reg_lambda': 2.9991596011021215, 'gamma': 0.2367594379070153, 'n_estimators': 601}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': len(classes),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 2.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 3.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 3.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 800)\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    preds = model.predict(X_test)\n",
    "    return f1_score(y_test, preds, average='weighted')\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ed346-68cf-4e8e-9f71-dd43566e817c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "\n",
    "# ================================\n",
    "# 1 DATA SPLITTING\n",
    "# ================================\n",
    "start = time()\n",
    "\n",
    "X = df_final.drop(['label'], axis=1)\n",
    "y = df_final['label']\n",
    "\n",
    "# Primeiro split: 70% treino, 30% restante\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Segundo split: 20% teste, 10% blind validation (dentro dos 30%)\n",
    "X_test, X_blind, y_test, y_blind = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.3333, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train_full.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "print(f\"Blind validation shape: {X_blind.shape}\")\n",
    "\n",
    "# ================================\n",
    "# 2 CLASS WEIGHTS (for imbalance)\n",
    "# ================================\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = np.unique(y_train_full)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train_full)\n",
    "weights = weights / np.mean(weights)  # normalize around 1.0\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3 STRATIFIED K-FOLD TRAINING\n",
    "# ================================\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full, y_train_full), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
    "    y_train, y_val = y_train_full.iloc[train_idx], y_train_full.iloc[val_idx]\n",
    "\n",
    "    # ================================\n",
    "    # 4 XGBOOST MODEL\n",
    "    # ================================\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        learning_rate=0.05,   # back to your original\n",
    "        max_depth=5,\n",
    "        n_estimators=800,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1,\n",
    "        reg_alpha=0,\n",
    "        gamma=0,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        sample_weight=y_train.map(class_weights),\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # ================================\n",
    "    # 5 VALIDATION RESULTS\n",
    "    # ================================\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred_val)\n",
    "    f1 = f1_score(y_val, y_pred_val, average='weighted')\n",
    "    print(f\"Validation Accuracy: {acc:.4f} | F1-score: {f1:.4f}\")\n",
    "    fold_results.append({'fold': fold, 'accuracy': acc, 'f1': f1})\n",
    "\n",
    "# Resultados mdios\n",
    "acc_mean = np.mean([r['accuracy'] for r in fold_results])\n",
    "f1_mean = np.mean([r['f1'] for r in fold_results])\n",
    "print(f\"\\nMdia Validation Accuracy: {acc_mean:.4f}\")\n",
    "print(f\"Mdia Validation F1-score: {f1_mean:.4f}\")\n",
    "\n",
    "# ================================\n",
    "# 6 TRAIN FINAL MODEL ON FULL TRAIN SET\n",
    "# ================================\n",
    "final_model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    eval_metric='mlogloss',\n",
    "    learning_rate=0.05,   # back to your original\n",
    "    max_depth=5,\n",
    "    n_estimators=800,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1,\n",
    "    reg_alpha=0,\n",
    "    gamma=0,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_train_full, y_train_full,\n",
    "    sample_weight=y_train_full.map(class_weights),\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 7 FEATURE IMPORTANCE\n",
    "# ================================\n",
    "feat_imp = pd.Series(final_model.feature_importances_, index=X_train_full.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 15 feature importances:\")\n",
    "print(feat_imp.head(15))\n",
    "\n",
    "# ================================\n",
    "# 8 TEST EVALUATION\n",
    "# ================================\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "print(\"\\nTest set results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_test, y_pred_test, average='weighted'):.4f}\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "ConfusionMatrixDisplay.from_estimator(final_model, X_test, y_test)\n",
    "\n",
    "# ================================\n",
    "# 9 BLIND VALIDATION\n",
    "# ================================\n",
    "y_pred_blind = final_model.predict(X_blind)\n",
    "print(\"\\nBlind validation results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_blind, y_pred_blind):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_blind, y_pred_blind, average='weighted'):.4f}\")\n",
    "print(classification_report(y_blind, y_pred_blind))\n",
    "ConfusionMatrixDisplay.from_estimator(final_model, X_blind, y_blind)\n",
    "\n",
    "print(\"\\nTotal time:\", round(time() - start, 2), \"seconds\")\n",
    "\n",
    "# ===================================================\n",
    "#  (OPTIONAL) OPTUNA HYPERPARAMETER TUNING BLOCK\n",
    "# ===================================================\n",
    "\"\"\"\n",
    "import optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': len(classes),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 2.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 3.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 3.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 800)\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**params, use_label_encoder=False)\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    preds = model.predict(X_test)\n",
    "    return f1_score(y_test, preds, average='weighted')\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b8bca49-a8d6-4265-bbbc-dd91c5cee1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4592, 10)\n",
      "Test shape: (1312, 10)\n",
      "Blind validation shape: (656, 10)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.766 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.780 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.740 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.777 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.771 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.782 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.770 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.784 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.767 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.751 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.781 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.770 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.762 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.785 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.768 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.784 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.773 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.760 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.765 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.769 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.766 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.788 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.770 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.783 total time=   4.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.768 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.769 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.765 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.775 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.766 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.778 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.785 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.776 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.794 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.775 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.773 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.768 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.789 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.781 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.786 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.779 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.776 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.778 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.785 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.769 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.777 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.788 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.791 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.783 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.776 total time=   3.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.777 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.788 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.791 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.770 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.780 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.781 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.780 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.786 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.769 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.784 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.781 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.776 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.763 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.768 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.767 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.779 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.769 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.755 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.790 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.750 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.780 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.769 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.780 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.770 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.763 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.781 total time=   3.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.783 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.776 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.781 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.766 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.784 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.772 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.779 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.785 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.789 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.784 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.776 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.774 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.782 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.772 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.794 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.779 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.794 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.777 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.786 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.775 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.791 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.778 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.775 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.779 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.778 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.788 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.771 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.778 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.782 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.781 total time=   3.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.770 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.768 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.774 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.782 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.780 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.770 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.781 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.788 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.782 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.775 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.792 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.779 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.774 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.783 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.772 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.777 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8;, score=0.781 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.781 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.766 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.755 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.749 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.789 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.771 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.785 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.773 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.785 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.773 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.785 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.779 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.768 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.789 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.761 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.785 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.778 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.774 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.775 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.777 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.792 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.770 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.765 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.789 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.771 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.786 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.777 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.776 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.775 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.785 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.780 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.792 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.779 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.774 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.786 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.777 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.788 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.776 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.773 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.791 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.781 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.791 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.777 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.770 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.790 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.784 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.776 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.781 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.783 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.770 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.778 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.782 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.783 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.778 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.776 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.783 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.780 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.773 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.767 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8;, score=0.788 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.776 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.746 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.781 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.784 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.765 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.756 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.788 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.772 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.767 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.781 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.774 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.752 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.783 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.770 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.785 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.778 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.758 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.780 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.767 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.777 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.769 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.771 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.783 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.770 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.795 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.770 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.780 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.790 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.784 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.764 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.775 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.789 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.776 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.773 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.790 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.790 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.785 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.791 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.776 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.768 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.778 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.790 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.778 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.773 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.783 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.778 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.789 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.779 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.767 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.776 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.774 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.796 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.781 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.792 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.779 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.785 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.785 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8;, score=0.775 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8;, score=0.790 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.786 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8;, score=0.773 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8;, score=0.785 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8;, score=0.777 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0;, score=0.778 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0;, score=0.789 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8;, score=0.775 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0;, score=0.778 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.783 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.784 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.769 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.782 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.764 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.771 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.784 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.762 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.752 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.786 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.768 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.779 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.784 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.770 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.756 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.775 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.768 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.770 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.766 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.761 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.773 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.786 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.766 total time=   5.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.778 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.768 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.770 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.761 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.770 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.794 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.768 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.780 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.795 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.769 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.782 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.770 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.778 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.773 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.771 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.792 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.780 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.785 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.767 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.766 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.786 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.770 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.790 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.790 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.784 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.770 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.786 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.771 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.784 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.777 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.783 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.785 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.783 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.771 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.788 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8;, score=0.778 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0;, score=0.781 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8;, score=0.776 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0;, score=0.776 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0;, score=0.782 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.760 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.769 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.746 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.788 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.775 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.786 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.765 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.751 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.773 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.769 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.760 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.763 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.784 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.765 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.777 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.760 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.767 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.780 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.764 total time=   5.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.770 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.781 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.782 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8;, score=0.790 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.764 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.788 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.775 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.785 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.777 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.776 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.791 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.777 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.779 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.781 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.776 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.782 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.778 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.784 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.780 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.763 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.778 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.777 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.790 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.781 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.768 total time=   4.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.773 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.792 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.770 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.780 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.779 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.770 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.778 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.781 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.777 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.793 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.785 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.783 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.782 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.780 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8;, score=0.783 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.775 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8;, score=0.786 total time=   3.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0;, score=0.778 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8;, score=0.768 total time=   3.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8;, score=0.785 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0;, score=0.771 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.776 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.754 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.790 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.755 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.751 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.783 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.771 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.788 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.768 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.750 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.777 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.771 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.784 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.765 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.753 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.761 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.765 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.780 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.771 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.757 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.775 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.776 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.790 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.770 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.793 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.773 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.773 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.788 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.766 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.791 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.790 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.779 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.789 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.779 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.773 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.786 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.763 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.789 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.773 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.773 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.789 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.780 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.786 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.776 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.774 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.774 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.774 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.771 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.783 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.774 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0;, score=0.776 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8;, score=0.790 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0;, score=0.778 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.748 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.758 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8;, score=0.773 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.744 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0;, score=0.780 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8;, score=0.768 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0;, score=0.783 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.769 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8;, score=0.791 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0;, score=0.776 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.780 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.761 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.757 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.788 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.767 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.785 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.763 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.749 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8;, score=0.779 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0;, score=0.770 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8;, score=0.782 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0;, score=0.762 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.767 total time=   6.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8;, score=0.782 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0;, score=0.768 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0;, score=0.782 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8;, score=0.781 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.771 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0;, score=0.789 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8;, score=0.778 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0;, score=0.792 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=0.779 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.758 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0;, score=0.783 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=0.780 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=0.782 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=0.781 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.776 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=0.779 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8;, score=0.784 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0;, score=0.782 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8;, score=0.781 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.767 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0;, score=0.783 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8;, score=0.779 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0;, score=0.781 total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.778 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.780 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8;, score=0.773 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0;, score=0.770 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.775 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8;, score=0.778 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0;, score=0.786 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8;, score=0.780 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0;, score=0.784 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.787 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.775 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.784 total time=   1.1s\n",
      "\n",
      "Melhores hiperparmetros encontrados:\n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 300, 'subsample': 0.8}\n",
      "\n",
      "Test set results:\n",
      "AUC (weighted, OVR): 0.8378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86       936\n",
      "           1       0.64      0.39      0.48       137\n",
      "           2       0.67      0.44      0.53       239\n",
      "\n",
      "    accuracy                           0.78      1312\n",
      "   macro avg       0.71      0.58      0.62      1312\n",
      "weighted avg       0.76      0.78      0.76      1312\n",
      "\n",
      "\n",
      "Blind validation results:\n",
      "AUC (weighted, OVR): 0.8364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       468\n",
      "           1       0.54      0.31      0.39        68\n",
      "           2       0.69      0.47      0.56       120\n",
      "\n",
      "    accuracy                           0.78       656\n",
      "   macro avg       0.68      0.57      0.60       656\n",
      "weighted avg       0.76      0.78      0.76       656\n",
      "\n",
      "\n",
      "Feature importances:\n",
      "st_disterr1       0.191193\n",
      "pl_insol          0.119432\n",
      "st_tmag           0.115148\n",
      "st_dist           0.104338\n",
      "pl_eqt            0.091221\n",
      "pl_rade           0.083351\n",
      "pl_tranmid        0.082476\n",
      "st_disterr2       0.080957\n",
      "pl_tranmiderr2    0.067293\n",
      "pl_radeerr2       0.064591\n",
      "dtype: float32\n",
      "Time: 296.6679391860962\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "# Features e label\n",
    "X = df_final.drop(['label'], axis=1)\n",
    "y = df_final['label']\n",
    "\n",
    "# Split: 70% treino, 30% restante (teste + blind validation)\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Split: 20% teste, 10% blind validation\n",
    "X_test, X_blind, y_test, y_blind = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.3333, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train_full.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "print(f\"Blind validation shape: {X_blind.shape}\")\n",
    "\n",
    "# StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Modelo XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',  # Multiclasse\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "\n",
    "# Grid de hiperparmetros\n",
    "param_grid = {\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# GridSearchCV com scoring para AUC multiclasse (One-vs-Rest)\n",
    "grid = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # AUC multiclasse\n",
    "    cv=cv,\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treinar\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"\\nMelhores hiperparmetros encontrados:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Melhor modelo\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Avaliao no teste\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_proba_test = best_model.predict_proba(X_test)\n",
    "auc_test = roc_auc_score(y_test, y_proba_test, multi_class='ovr', average='weighted')\n",
    "print(\"\\nTest set results:\")\n",
    "print(f\"AUC (weighted, OVR): {auc_test:.4f}\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Avaliao blind validation\n",
    "y_pred_blind = best_model.predict(X_blind)\n",
    "y_proba_blind = best_model.predict_proba(X_blind)\n",
    "auc_blind = roc_auc_score(y_blind, y_proba_blind, multi_class='ovr', average='weighted')\n",
    "print(\"\\nBlind validation results:\")\n",
    "print(f\"AUC (weighted, OVR): {auc_blind:.4f}\")\n",
    "print(classification_report(y_blind, y_pred_blind))\n",
    "\n",
    "# Feature importances\n",
    "feat_imp = pd.Series(best_model.feature_importances_, index=X_train_full.columns).sort_values(ascending=False)\n",
    "print(\"\\nFeature importances:\")\n",
    "print(feat_imp)\n",
    "\n",
    "end = time()\n",
    "print(\"Time:\", end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0ad51f6d-5974-4e33-8c19-bf93d9411bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4592, 10)\n",
      "Test shape: (1312, 10)\n",
      "Blind validation shape: (656, 10)\n",
      "\n",
      "Fold 1\n",
      "Validation Accuracy: 0.7802 | F1-score: 0.7664\n",
      "\n",
      "Fold 2\n",
      "Validation Accuracy: 0.7769 | F1-score: 0.7602\n",
      "\n",
      "Fold 3\n",
      "Validation Accuracy: 0.7930 | F1-score: 0.7776\n",
      "\n",
      "Fold 4\n",
      "Validation Accuracy: 0.7778 | F1-score: 0.7642\n",
      "\n",
      "Fold 5\n",
      "Validation Accuracy: 0.7952 | F1-score: 0.7797\n",
      "\n",
      "Mdia Validation Accuracy: 0.7846\n",
      "Mdia Validation F1-score: 0.7696\n",
      "\n",
      "Feature importances:\n",
      "st_disterr1       0.191193\n",
      "pl_insol          0.119432\n",
      "st_tmag           0.115148\n",
      "st_dist           0.104338\n",
      "pl_eqt            0.091221\n",
      "pl_rade           0.083351\n",
      "pl_tranmid        0.082476\n",
      "st_disterr2       0.080957\n",
      "pl_tranmiderr2    0.067293\n",
      "pl_radeerr2       0.064591\n",
      "dtype: float32\n",
      "\n",
      "Test set results:\n",
      "Accuracy: 0.7797\n",
      "F1-score: 0.7612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86       936\n",
      "           1       0.64      0.39      0.48       137\n",
      "           2       0.67      0.44      0.53       239\n",
      "\n",
      "    accuracy                           0.78      1312\n",
      "   macro avg       0.71      0.58      0.62      1312\n",
      "weighted avg       0.76      0.78      0.76      1312\n",
      "\n",
      "\n",
      "Blind validation results:\n",
      "Accuracy: 0.7759\n",
      "F1-score: 0.7566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       468\n",
      "           1       0.54      0.31      0.39        68\n",
      "           2       0.69      0.47      0.56       120\n",
      "\n",
      "    accuracy                           0.78       656\n",
      "   macro avg       0.68      0.57      0.60       656\n",
      "weighted avg       0.76      0.78      0.76       656\n",
      "\n",
      "Time: 5.014374732971191\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "# Features e label\n",
    "X = df_final.drop(['label'], axis=1)\n",
    "y = df_final['label']\n",
    "\n",
    "# Primeiro split: 70% treino, 30% restante\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Segundo split: 20% teste, 10% blind validation (dentro dos 30% restantes)\n",
    "X_test, X_blind, y_test, y_blind = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.3333, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train_full.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "print(f\"Blind validation shape: {X_blind.shape}\")\n",
    "\n",
    "# Stratified K-Fold dentro do conjunto de treino (70%)\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full, y_train_full), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
    "    y_train, y_val = y_train_full.iloc[train_idx], y_train_full.iloc[val_idx]\n",
    "\n",
    "    # Modelo XGBoost padro\n",
    "    model = xgb.XGBClassifier(eval_metric='mlogloss',objective='multi:softprob',colsample_bytree=1.0,\n",
    "                              learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Avaliao do fold\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred_val)\n",
    "    f1 = f1_score(y_val, y_pred_val, average='weighted')\n",
    "    print(f\"Validation Accuracy: {acc:.4f} | F1-score: {f1:.4f}\")\n",
    "    fold_results.append({'fold': fold, 'accuracy': acc, 'f1': f1})\n",
    "\n",
    "# Resultados mdios dos folds\n",
    "acc_mean = np.mean([r['accuracy'] for r in fold_results])\n",
    "f1_mean = np.mean([r['f1'] for r in fold_results])\n",
    "print(f\"\\nMdia Validation Accuracy: {acc_mean:.4f}\")\n",
    "print(f\"Mdia Validation F1-score: {f1_mean:.4f}\")\n",
    "\n",
    "# Treina modelo final no treino completo\n",
    "final_model_tuned = xgb.XGBClassifier(eval_metric='mlogloss',objective='multi:softprob',colsample_bytree=1.0,\n",
    "                              learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8)\n",
    "final_model_tuned.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Feature importances\n",
    "feat_imp = pd.Series(final_model_tuned.feature_importances_, index=X_train_full.columns).sort_values(ascending=False)\n",
    "print(\"\\nFeature importances:\")\n",
    "print(feat_imp)\n",
    "\n",
    "# Avaliao no teste\n",
    "y_pred_test = final_model_tuned.predict(X_test)\n",
    "print(\"\\nTest set results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_test, y_pred_test, average='weighted'):.4f}\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Avaliao na blind validation\n",
    "y_pred_blind = final_model_tuned.predict(X_blind)\n",
    "print(\"\\nBlind validation results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_blind, y_pred_blind):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_blind, y_pred_blind, average='weighted'):.4f}\")\n",
    "print(classification_report(y_blind, y_pred_blind))\n",
    "end = time()\n",
    "print(\"Time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "151ca03c-6184-48e4-a11c-a9e1c3bc76dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blind.to_csv('./models/tess/X_blind.csv')\n",
    "y_blind.to_csv('./models/tess/y_blind.csv')\n",
    "final_model_tuned.save_model(\"./models/tess/tess_model.json\")\n",
    "final_model_tuned.save_model(\"./models/tess/tess_model_tuned.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218447a-9213-42a8-a439-d5586de2fd3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testar no Dataset todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b935fcbe-1e76-48ba-b32a-9eab886e8cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 0.7245509648000891, 10: 0.7661928858736956, 15: 0.775993252886986, 20: 0.7860609093773749, 30: 0.7996715416411797, 52: 0.7955858310626703}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Ordena importncias\n",
    "feat_imp = pd.Series(final_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "results = {}\n",
    "for k in [5, 10, 15, 20, 30, len(feat_imp)]:\n",
    "    selected = feat_imp.index[:k]\n",
    "    scores = cross_val_score(\n",
    "        xgb.XGBClassifier(eval_metric='mlogloss'),\n",
    "        X_train[selected],\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\"\n",
    "    )\n",
    "    results[k] = np.mean(scores)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50808280-3798-4e5e-adc0-97243128de67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
